import operational_sep_quantities as sep
from library import ccmc_json_handler as ccmc_json
from library import keys
from library import global_vars as gl
from importlib import reload
import matplotlib.pyplot as plt
import argparse
import csv
import datetime
import logging
import sys
import os
import asciitable

__version__ = "0.5"
__author__ = "Katie Whitman"
__maintainer__ = "Katie Whitman"
__email__ = "kathryn.whitman@nasa.gov"

#Changes in 0.2: Modified so that output list files will indicate when an
#   observation or flux did not exceed a certain threshold for a given SEP
#   event. Added a column specifying SEP date to sep_list
#2021-01-14, Changes in 0.3: Made consistent with operational_sep_quantities.py
#   v2.3 which includes background subtraction and various energy bin options.
#   Added more fields to list file to allow better specification of each data
#   set.
#2021-02-24, Changes in 0.4: Read in json files produced by
#   operational_sep_quantities.py and then write certain quantities to list.
#2021-04-05, Changes in 0.4.1: Reads pathnames from library/global_vars.py.
#   Added checking for listpath. Code will check for listpath and create.
#2021-05-17, changes in 0.5: Discovered differences in CCMC's json files.
#   Making changes here to be consistent with their format. CCMC defines
#   "fluences" and "event_lengths" as arrays.


datapath = gl.datapath
outpath = gl.outpath
listpath = gl.listpath

logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger('sep')
logging.getLogger("matplotlib").setLevel(logging.WARNING)

############## SET INPUTS ##################
showplot = False
saveplot = True
detect_prev_event_default = False #Set to true if get FirstStart flag
two_peaks_default = False #Set to true if get ShortEvent flag
############## END INPUTS #################


def about_run_multi_sep():
    """This and supporting codes are found in the respository:
            https://github.com/ktindiana/operational-sep

        This code will run operational_sep_quantities.py for multiple SEP events.

        The input list file specifying which time periods must follow the format
        below. The SEP dates will be read in from a csv file with the columns:
        
            :Start Date: YYYY-MM-DD or YYYY-MM-DD HH:MM:SS
            :End Date: YYYY-MM-DD or YYYY-MM-DD HH:MM:SS
            :Experiment: GOES-08 up to GOES-15, EPHIN, SEPEM, SEPEMv3, user
            :Flux Type: differential or integral
            :Flags: Options are blank, TwoPeak, DetectPreviousEvent, and/ or SubtractBG separated by semi-colons, e.g. TwoPeak;SubtractBG
            :Model Name: blank if not a model
            :User Filename: name of file containing SEP time profile that user wants to input
            :options: may be "S14;Bruno2017;uncorrected"
            :Background Start Date: YYYY-MM-DD or YYYY-MM-DD HH:MM:SS (if subtracting a BG)
            :Background End Date: YYYY-MM-DD or YYYY-MM-DD HH:MM:SS
        
        COLUMN ENTRIES FOR OBSERVATIONS:
        
        StartDate, Enddate, Experiment, FluxType, Flags,,,options, bgstartdate, bgenddate
        
        COLUMN ENTRIES FOR 'user' FILE:
        
        StartDate, Enddate, Experiment, FluxType, Flags, Model Name, User Filename, options, bgstartdate, bgenddate

      
        OUTPUT FILES INCLUDE:
        
            * All of the output files generated by operational_sep_quantities.py
        
            * An aggregated list of information for all of the SEP events for each of the thresholds containing:
        
                * Start Time,End Time,Onset Peak Flux,Onset Peak Time,Max Flux, Max Flux Time,Fluence
        
            * If UMASEP, then the additional columns:
        
                * Ts + 3hr, Ts + 4hr, Ts + 5hr, Ts + 6hr, Ts + 7hr
    """

def check_list_path():
    if not os.path.isdir(listpath):
        print('check_paths: Directory containing lists, ' + listpath +
        ', does not exist. Creating.')
        os.mkdir(listpath);



def read_sep_dates(sep_filename):
    ''' Reads in a csv list file of SEP events. List must have the format:
        
        StartDate, Enddate, Experiment, FluxType, Flags,,,options,bgstartdate,
            bgenddate
        
        If the experiment is 'user', indicating a user-input flux file, then
        the file must have the format:
        
        StartDate, Enddate, Experiment, FluxType, Flags, Model Name,
            User Filename, options, bgstartdate, bgenddate

        Flags may be: TwoPeak, DetectPreviousEvent, SubtractBG
        
        options may be: "S14,Bruno2017,uncorrected"
    '''
    print('Reading in file ' + sep_filename)
    start_dates = [] #row 0
    end_dates = []
    experiments = [] #row 1, e.g. GOES-11, GOES-13, GOES-15, SEPEM, user
    flux_types = [] #row 3
    flags = [] #row 4
    model_names = [] #row 5
    user_files = [] #row 6
    options = [] #row 7
    bgstartdate = [] #row 8
    bgenddate = [] #row 9

    with open(sep_filename) as csvfile:
        readCSV = csv.reader(csvfile, delimiter=',')
        #Define arrays that hold dates
        for row in readCSV:
            chk = row[0].lstrip()
            if chk[0] == '#': continue #skip if header row
            if len(row[0]) > 10:
                stdate = datetime.datetime.strptime(row[0][0:19],
                                            "%Y-%m-%d %H:%M:%S")
            if len(row[0]) == 10:
                stdate = datetime.datetime.strptime(row[0][0:10],
                                            "%Y-%m-%d")
            if len(row[1]) > 10:
                enddate = datetime.datetime.strptime(row[1][0:19],
                                            "%Y-%m-%d %H:%M:%S")
            if len(row[1]) == 10:
                enddate = datetime.datetime.strptime(row[1][0:10],
                                            "%Y-%m-%d")
            start_dates.append(str(stdate))
            end_dates.append(str(enddate))
            experiments.append(row[2])
            flux_types.append(row[3])

            if len(row) > 4:
                flags.append(row[4])
            else:
                flags.append('')

            if len(row) > 5:
                model_names.append(row[5])
            else:
                model_names.append('')

            if len(row) > 6:
                user_files.append(row[6])
            else:
                user_files.append('')

            if len(row) > 7:
                options.append(row[7])
            else:
                options.append('')

            if len(row) > 8:
                bgstartdate.append(row[8])
            else:
                bgstartdate.append('')

            if len(row) > 9:
                bgenddate.append(row[9])
            else:
                bgenddate.append('')


            if row[1] == 'user':
                if len(row) < 7:
                    sys.exit("For a user file, you must specify model name and "
                            "input filename in the list.")


    return start_dates, end_dates, experiments, flux_types, flags, model_names,\
        user_files, options, bgstartdate, bgenddate



def initialize_files(jsonfname):
    '''Initialize the output files that will contain the sep quantities.'''
    data = ccmc_json.read_in_json(jsonfname)
    if keys.obs_main in data:  #observations
        key_main = keys.obs_main
        key_exp = keys.obs_exp
        key_type = keys.obs_type
        key_win = keys.obs_win
    if keys.model_main in data: #model
        key_main = keys.model_main
        key_exp = keys.model_exp
        key_type = keys.model_type
        key_win = keys.model_win
        
    #Identify number of thresholds in the json file
    nthresh = len(data[key_main][key_type])
    for i in range(nthresh):
        energy_min = data[key_main][key_type][i]['energy_channel']['min']
        energy_max = data[key_main][key_type][i]['energy_channel']['max']
        thresh = data[key_main][key_type][i]['event_lengths'][0]['threshold']
        
        #Create an output file to contain list of calculated
        #quantities for all SEPs in input list
        #NOTE WILL WRITE OVER LIST FROM PREVIOUS RUNS UNLESS RENAMED
        if energy_max == -1:  #integral channel
            threshfile = listpath + '/' +'sep_list_' + str(energy_min) + 'MeV_' \
                    + str(thresh) + 'pfu.csv'
            bin_def = '>'+str(energy_min) + ' MeV [cm-2 sr-1]'
        else:
            threshfile = listpath + '/' +'sep_list_' + str(energy_min) +'-'\
                    + str(energy_max) + 'MeV_' + str(thresh) + 'dpfu.csv'
            bin_def = str(energy_min) + '-' + str(energy_max) + ' MeV [MeV-1 cm-2 sr-1]'
        
        fin = open(threshfile,'w+')
        fin.write('#Experiment,SEP Date,Start Time,End Time,Onset Peak Flux,'
                    'Onset Peak Time,Max Flux,Max Flux Time,Fluence '+bin_def)
        fin.write('\n')
        fin.close()
        print('Created file ' + threshfile)
    
    return


def write_sep_lists(jsonfname):
    ''' Reads in sep_values_*.json files output by operational_sep_quantities.
        Selected information is taken and sorted into lists for each threshold
        definition. Output is then an SEP list with associated quantities for
        each threshold.
        
        In the output list file, None or null values indicate that the model
        or observations did not cross threshold.
    '''
    
    data = ccmc_json.read_in_json(jsonfname)
    if keys.obs_main in data:  #observations
        key_main = keys.obs_main
        key_exp = keys.obs_exp
        key_type = keys.obs_type
        key_win = keys.obs_win
    if keys.model_main in data: #model
        key_main = keys.model_main
        key_exp = keys.model_exp
        key_type = keys.model_type
        key_win = keys.model_win
    
   
    exp_name = data[key_main][key_exp]['short_name']
    
    #Identify number of thresholds in the json file
    nthresh = len(data[key_main][key_type])
    for i in range(nthresh):
        energy_min = data[key_main][key_type][i]['energy_channel']['min']
        energy_max = data[key_main][key_type][i]['energy_channel']['max']
        thresh = data[key_main][key_type][i]['event_lengths'][0]['threshold']
        
        #Open or create an output file to contain list of calculated
        #quantities for all SEPs in input list
        #NOTE WILL WRITE OVER LIST FROM PREVIOUS RUNS UNLESS RENAMED
        if energy_max == -1:  #integral channel
            threshfile = listpath + '/' +'sep_list_' + str(energy_min) + 'MeV_' \
                    + str(thresh) + 'pfu.csv'
        else:
            threshfile = listpath + '/' +'sep_list_' + str(energy_min) +'-'\
                    + str(energy_max) + 'MeV_' + str(thresh) + 'dpfu.csv'
        
        isgood = os.path.isfile(threshfile)
        if not isgood:
            #In case a new threshold is encoutered
            bin_def = '>'+str(energy_min) + ' MeV [cm-2 sr-1]'
            if energy_max != -1:
                bin_def = str(energy_min) + '-' + str(energy_max) + ' MeV [MeV-1 cm-2 sr-1]'
            fin = open(threshfile,'w+')
            fin.write('#Experiment,SEP Date,Start Time,End Time,Onset Peak Flux,'
                    'Onset Peak Time,Max Flux,Max Flux Time,Fluence ' + bin_def)
            fin.write('\n')
            fin.close()
            print('Creating file ' + threshfile)

        #Pick out columns to extract and save to SEP list
        #start time, onset peak, onset time, peak flux, peak time, end time, fluence
        #If UMASEP, then all delayed proton values <---EDIT TO INCLUDE IN OUTPUT
        zst = data[key_main][key_type][i]['event_lengths'][0]['start_time']
        start_time = ccmc_json.zulu_to_time(zst)
        if start_time == '' or start_time == None: #NO SEP EVENT FOR THRESHOLD
            continue
        sep_year = start_time.year
        sep_month = start_time.month
        sep_day = start_time.day
        zet = data[key_main][key_type][i]['event_lengths'][0]['end_time']
        end_time = ccmc_json.zulu_to_time(zet)
        
        onset_peak = data[key_main][key_type][i]['peak_intensity']['intensity']
        zopt = data[key_main][key_type][i]['peak_intensity']['time']
        onset_peak_time = ccmc_json.zulu_to_time(zopt)
        
        max_flux = data[key_main][key_type][i]['peak_intensity_esp']['intensity']
        zmft = data[key_main][key_type][i]['peak_intensity_esp']['time']
        max_flux_time = ccmc_json.zulu_to_time(zmft)
        
        fluence = data[key_main][key_type][i]['fluences'][0]['fluence_value']
        
        #WRITE QUANTITIES TO FILE
        fin = open(threshfile,'a')
        fin.write(exp_name + ',')
        date = '{0:d}-{1:02d}-{2:02d}'.format(sep_year, sep_month,sep_day)
        fin.write(date + ',')
        fin.write(str(start_time) + ',')
        fin.write(str(end_time) + ',')
        fin.write(str(onset_peak) + ',')
        fin.write(str(onset_peak_time) + ',')
        fin.write(str(max_flux) + ',')
        fin.write(str(max_flux_time) + ',')
        fin.write(str(fluence))
        #Add code to include UMASEP cols when get chance (those values
        #need to be added to JSON file first)
        fin.write('\n')
        fin.close()

    return True



if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--Filename", type=str, default='tmp.csv', \
            help=("Name of csv file containing list of SEP start dates and files."
            "Default is tmp.csv."))
    parser.add_argument("--OutFilename", type=str, default='lists/out.csv', \
            help=("Name of csv file containing list of SEP dates with "
                "flags indicating status after run with "
                "operational_sep_quantities.py. Default is lists/out.csv."))
    parser.add_argument("--Threshold", type=str, default="100,1",
            help=("An additional energy and flux threshold (written as 100,1 "
                    "with no spaces) which will be used to define the event. "
                    "e.g. 100,1 indicates >100 MeV fluxes crossing 1 pfu "
                    "(1/[cm^2 s sr]). Default = '100,1'"))
    parser.add_argument("--UMASEP",
            help=("Flag to calculate flux values and thresholds specific to "
                "the UMASEP model. Thresholds for >10, >30, >50, >100 MeV and "
                "flux values at 3, 4, 5, 6, 7 hours after "
                "crossing thresholds."), action="store_true")

    args = parser.parse_args()
    sep_filename = args.Filename
    outfname = args.OutFilename
    threshold = args.Threshold
    umasep = args.UMASEP
    
    check_list_path()

    #READ IN SEP DATES AND experiments
    start_dates, end_dates, experiments, flux_types, flags, model_names, \
        user_files, options, bgstart, bgend = read_sep_dates(sep_filename)

    #Prepare output file listing events and flags
    fout = open(outfname,"w+")
    fout.write('#Experiment,SEP Date,Exception\n')

    #---RUN ALL SEP EVENTS---
    Nsep = len(start_dates)
    print('Read in ' + str(Nsep) + ' SEP events.')
    for i in range(Nsep):
        start_date = start_dates[i]
        end_date = end_dates[i]
        experiment = experiments[i]
        flux_type = flux_types[i]
        flag = flags[i]
        model_name = model_names[i]
        user_file = user_files[i]
        option = options[i]
        bgstartdate = bgstart[i]
        bgenddate = bgend[i]
        
        spase_id = ''

        flag = flag.split(';')
        detect_prev_event = detect_prev_event_default
        two_peaks = two_peaks_default
        doBGSub = False
        nointerp = False #if true, will not do interpolation in time
        if "DetectPreviousEvent" in flag:
            detect_prev_event = True
        if "TwoPeak" in flag:
            two_peaks = True
        if "SubtractBG" in flag:
            doBGSub = True

        print('\n-------RUNNING SEP ' + start_date + '---------')
        #CALCULATE SEP INFO AND OUTPUT RESULTS TO FILE
        try:
            sep_year, sep_month, \
            sep_day, jsonfname = sep.run_all(start_date, end_date, experiment, flux_type, model_name, user_file,
                spase_id, showplot, saveplot, detect_prev_event,
                two_peaks, umasep, threshold, option, doBGSub, bgstartdate,
                bgenddate, nointerp)

            sep_date = datetime.datetime(year=sep_year, month=sep_month,
                            day=sep_day)
            if experiment == 'user' and model_name != '':
                fout.write(model_name + ',')
            if experiment != 'user':
                fout.write(experiment + ',')
            fout.write(str(sep_date) + ', ')
            fout.write('Success\n')

            #COMPILE QUANTITIES FROM ALL SEP EVENTS INTO A SINGLE LIST FOR
            #EACH THRESHOLD
            if i==0:
                initialize_files(jsonfname)
            success=write_sep_lists(jsonfname)
            if not success:
                print('Could not write values to file for ' + jsonfname)

            plt.close('all')
            sep = reload(sep)
            gl = reload(gl)

        except SystemExit as e:
            # this log will include traceback
            logger.exception('operational_sep_quantities failed with exception')
            # this log will just include content in sys.exit
            logger.error(str(e))
            if experiment == 'user' and model_name != '':
                fout.write(model_name + ',')
            if experiment != 'user':
                fout.write(experiment + ',')
            fout.write(str(start_date) +',' + '\"' + str(e) + '\"' )
            fout.write('\n')
            sep = reload(sep)
            gl = reload(gl)
            continue

    fout.close()
